# 코드구현

코드는 1장에서 사용한 함수들을 대부분 가져다 사용하고 있습니다.

```python
def pulsar_exec(self, epoch_count=10, mb_size=10, report=1):
    self.load_pulsar_dataset()
    self.init_model()
    self.train_and_test(epoch_count, mb_size, report)
```

```python
def load_pulsar_dataset(self):
    with open('./pulsar_stars.csv') as csvfile:
        csvreader = csv.reader(csvfile)
        next(csvreader, None)
        rows = []

        for row in csvreader:
            rows.append(row)
        print(len(rows))
        self.input_cnt, self.output_cnt = 8, 1
        self.data = np.asarray(rows, dtype='float32')
        print(self.data.shape)
```

이장에서 사용될 데이터는 8가지의 입력데이터와 1가지의 출력데이터를 사용하였습니다.
즉, **X**(17898, 8), **Y**(17989, 1)이 됩니다.
np.asarray는 data type이 같다면 array를 생성하지 않고 다를때 array를 생성합니다.

```python
def arrange_data(self, mb_size):
    self.shuffle_map = np.arange(self.data.shape[0])
    np.random.shuffle(self.shuffle_map)
    step_count = int(self.data.shape[0] * 0.8) // mb_size
    self.test_begin_idx = step_count * mb_size
    return step_count
```

data의 순서를 섞고 train data와 test data로 나눕니다. 이때, mb_size(미니배치 사이즈 = 10)을 바탕으로 미니배치갯수(1431)를 정하게 됩니다. train data와 test data를 나누는 idx(test_begin_idx)는 14310이 됩니다.

```python
def get_test_data(self):
    test_data = self.data[self.shuffle_map[self.test_begin_idx:]]
    return test_data[:, :-self.output_cnt], test_data[:, -self.output_cnt:]

def get_train_data(self, mb_size, nth):
    if nth == 0:
        np.random.shuffle(self.shuffle_map[:self.test_begin_idx])
    train_data = self.data[self.shuffle_map[mb_size * nth:mb_size * (nth + 1)]]

    return train_data[:, :-self.output_cnt], train_data[:, -self.output_cnt:]

```

test_data_x의 형태는 [3855, 8], test_data_y의 형태는 [3855, 1]이 됩니다.
train_data는 mb_size(미니배치 크기, 10) 만큼 나뉘게 됩니다.
train_data_x의 형태는 [10, 8], train_data_y의 형태는 [10, 1]이 됩니다.

```python
def forward_postproc(self, output, y):
    entropy = self.sigmoid_cross_entropy_with_logits(y, output)
    loss = np.mean(entropy)
    return loss, [y, output, entropy]

def relu(self, x):
    return np.maximum(x, 0)

def sigmoid_cross_entropy_with_logits(self, z, x):
    return self.relu(x) - x * z + np.log(1 + np.exp(-np.abs(x)))
```

테스트를 진행하게 되면 먼저  $\mathbf{Y}=\mathbf{X}\mathbf{W}+\mathbf{b} $ 를 계산합니다.(**Y**는 추정값)

그 후 시그모이드 교차엔트로피로 loss를 구하게 됩니다. 

교차엔트로피 *H*는 아래와 같이 계산하게 됩니다. 
$$
H=x-xz+log(1+e^{-x}) \\
z=0 일때 H=x +log(1+e^{-x}) \\
z=1 일때 H=log(1+e^{-x})
$$
이때 사용하게 되는 maximum 함수는 받은 행렬들의 원소를 각각 비교해서 큰 쪽을 출력합니다. 그래서 음수인 원소가 0으로 변경되어 출력 됩니다. 이는 음수인 원소들을 모두 찾아내 0으로 대치하는 효과가 있습니다.

```python
def backprop_postproc(self, G_loss, aux):
    y, output, entropy = aux
    
    g_loss_entropy = 1.0 / np.prod(entropy.shape)
    g_entropy_output = self.sigmoid_cross_entropy_with_logits_derv(y, output)
    
    G_entropy = g_loss_entropy * G_loss
    G_output = g_entropy_output * G_entropy

    return G_output


return G_output

def sigmoid(self, x):
    return np.exp(-self.relu(-x)) / (1.0 + np.exp(-np.abs(x)))

def sigmoid_cross_entropy_with_logits_derv(self, z, x):
    return -z + self.sigmoid(x)
```

역전파를 계산하게 됩니다.
역전파를 계산하기 위해 시그모이드 함수에 대한 교차엔트로피를 편미분 하게 됩니다. 식은 다음과 같습니다.

 먼저 
$$
{\partial L\over\partial {output}} = {\partial L\over\partial {H}}{\partial {H}\over\partial {output}}
$$
를 구하 되는데 ${\partial L\over\partial {entropy}}$ (g_loss_square,이때 n=10*1)과 ${\partial {entropy}\over\partial {diff}}$ 는 
$$
{\partial L\over\partial {H}}={1\over n}
$$

$$
\frac{\partial{H}}{\partial{output}}=\frac{\partial}{\partial{output}}(x-xz+\log{(1+e^-x)})\\=1-z+\frac{(1+e^{-x})^{'}}{1+e^{-x}}\\=1-z+\frac{-e^{-x}}{1+e^{-x}}\\=-z+\frac{1}{z+e^{-x}}\\=-z+\sigma(x)
$$

이후 ${\partial L\over\partial {output}}$(G_output[mb_size(10),1])와 입력행렬 **X**[mb_size(10),10]를 이용하여 ${\partial L\over\partial {w}}={X^T}G_{output}$ 와 ${\partial L\over\partial {b}}$ = G_output의 합를 구한 후 가중치와 편향값을 업데이트 하게 됩니다( $w_{i+1} = w_i-\alpha{\partial L\over\partial {w}} $ 와 $b_{i+1} = x_i-\alpha{\partial L\over\partial {b}} $ )

```python
def backprop_neuralnet(self, G_output, x):
    g_output_w = x.transpose()

    G_w = np.matmul(g_output_w, G_output) 
    G_b = np.sum(G_output, axis=0)

    self.weight -= self.LEARNING_RATE * G_w
    self.bias -= self.LEARNING_RATE * G_b
```



### 확장하기

여기서는 정밀도 , 재현율 정확도, f1을 사용하여 신경망의 성능을 여로 평가 지표로 보여주게 됩니다. 

- 정밀도 : 신경망이 참으로 추정한 것 가운데 정답이 참인 비율
  신경망도 참이고 정답도 참인 수/ 신경망이 참으로 추정한것들의 수를 분모
  $$
  정밀도 = {{TP} \over{TP+FP}}
  $$
  

- 재현율 : 정답이 참인 것들 가운데 신경망이 참으로 추정한 것의 비율
  신경망도 참이고 정답도 참인 수/ 정답이 참인 것들의 수

$$
재현율 = {{TP}\over{TP+TN}}
$$

- 정확도 : 전체 대답 가운데 옳은 대답의 비율
  참인 것을 참이라 답했거나 거짓인 것을 거짓이라 답한 비율
  $$
  정확도 = {{TP+FN}\over{TP+TN+FP+FN}}
  $$

- F1 : 정밀도와 재현율의 조화평균
  $$
  F1 = {{2*정밀도*재현율}\over{정밀도 + 재현율}}
  $$



```python
def eval_accuracy(self, output, y):
    est_yes = np.greater(output, 0)
    ans_yes = np.greater(y, 0.5)
    est_no = np.logical_not(est_yes)
    ans_no = np.logical_not(ans_yes)

    tp = np.sum(np.logical_and(est_yes, ans_yes))
    fp = np.sum(np.logical_and(est_yes, ans_no))
    fn = np.sum(np.logical_and(est_no, ans_yes))
    tn = np.sum(np.logical_and(est_no, ans_no))
    accuracy = self.safe_div(tp + tn, tp + tn + fp + fn)
    precision = self.safe_div(tp, tp + fp)
    recall = self.safe_div(tp, tp + fn)
    f1 = 2 * self.safe_div(recall * precision, recall + precision)

    return [accuracy, precision, recall, f1]
```

```
Epoch 1: loss=0.413, result=0.924,0.932,0.916,0.924
Epoch 2: loss=0.380, result=0.920,0.976,0.862,0.915
Epoch 3: loss=0.374, result=0.899,0.872,0.937,0.903
Epoch 4: loss=0.382, result=0.870,0.825,0.942,0.879
Epoch 5: loss=0.376, result=0.910,0.895,0.930,0.912
Epoch 6: loss=0.367, result=0.828,0.757,0.969,0.850
Epoch 7: loss=0.367, result=0.900,0.875,0.935,0.904
Epoch 8: loss=0.367, result=0.890,0.994,0.786,0.878
Epoch 9: loss=0.371, result=0.925,0.934,0.916,0.925
Epoch 10: loss=0.367, result=0.598,0.556,0.997,0.714

Final Test: final result = 0.598,0.556,0.997,0.714
```


# 3. 선택 분류

선택분류 문제는 몇가지 정해진 후보 가운데 하나를 골라 답하는 문제 입니다. 

이 장에서는 철판의 불량 상태 판별을 하게 되는데 7가지 종류의 불량 상태를 판별하게 됩니다.

선택 분류 신경망은 이진 판단에서 처럼 각 후보 항목에 대한 로그 척도의 상대적 추천강도, 즉 로짓 값을 추정하도록 구성됩니다.

> 로짓(logit) : 실제 표현하려는 값을 로그값으로 나타낸 것.

디때 퍼셉트론 하나가 후부 하나에 대한 로짓값을 출력하게 되므로 후보 수만큼의 퍼셉트론이 필요하게 됩니다.

또한 2장에서 사용한 교차 엔트로피를 선택 분류에도 적용하여 이를 손실 함수로 적용하여 학습을 수행하게 됩니다.

이때 교차 엔트로피를 계산해주는 함수를 소프트맥스 함수와 소프트맥스 교차 엔트로피 함수로 사용하게 됩니다.



## 3.1 소프트맥스 함수

소프트맥스 함수는 분류해야하는 정답지(클래스)의 총 개수를 k라고 할 때, k차원의 벡터를 입력받아 각 클래스에 대한 확률을 추정 할 수 있게 해줍니다.

소프트맥스 함수는 로짓값 벡터를 확률 분포 벡터로 변환해 주는 비선형 함수입니다.
$$
\mathbf{Y}(N,7)=\mathbf{X}(N,27)\mathbf{W}(27,7)+\mathbf{b}(N,7)
$$

위 식은 이번 데이터에관한 퍼셉트론 식이 됩니다.

이 결과는 미니 배치 데이터 N개에 대해 각각 7가지 후보들의 로짓값을 나타내는 벡터**Y**(1,7)들로 해석이 됩니다.

이 로짓값 벡터를 가지고도 순전파 처리가 가능 하지만, 확률 분포를 눈으로 확인하기 위해서나 역전파에서 손실 함수에 대한 편미분을 구할 때 확률 분포가 필요하기 때문에 필요합니다.

이때 확률 분포 벡터로 변환 해주는 소프트 맥스함수가 사용이 된다. 소프트 맥스 함수의 출력은 확률분포, 즉 각 후보 항목이 정답일 확률 값들로 구성된 벡터입니다.  또한 확률의 성질상 각 성분은 0 에서 1사이이고 모든 성분의 합이 1이 나와야 합니다.



### 일반식 도출

먼저 예시로 로짓값 벡터 (2.0,1.0,1.2,0.7)이 들어오면 각 로짓값에 대앙하는 실제확률은 ($e^{2.0},e^{1.0},e^{1.2},e^{0.7}$)

이 되고 이제 이 비율을 유지하면서 전체 합이 1이되는 비율을 구하면 (0.479:0.146:0.215:0.130) 이됩니다.

이를 수식으로 표현하게 되면 로짓값 벡터(입력벡터) {${x_1,x_2...,x_n}$} 에 대하여 $x_i$에 해당하는 실제 확률은 $e^{x_i}$에 비례하는 값이며 비례상수를 $\alpha$라 하면 $\alpha e^{x_i}$ 가 된다. 모든 확률 합이 1 되어어야 하므로
$$
{\alpha{e^{x_1}}+\alpha{e^{x_n2}}+...+\alpha{e^{x_n}}} = 1
$$
 이고 따라서 $\alpha$는 
$$
{\alpha} = {1\over{e^{x_1}}+{e^{x_n2}}+...+{e^{x_n}}}
$$
출력 벡터는 이와 같이 되고 일반식까지 도출하면 아래와 같이 됩니다.
$$
\left({{e^{x_1}}\over{e^{x_1}}+...+{e^{x_n}}},...,{{e^{x_n}}\over{e^{x_1}}+...+{e^{x_n}}}\right) \\\ \\
{y_i}={{e^{x_i}}\over{e^{x_1}}+...+{e^{x_n}}}
$$


하지만 이식은 꼐산과정에서 오류가 발생될 수 있습니다. 예로 범위 제약이 없는 $x$값들이 마구자비로 커지는 바람에  $e^{x_i}$의 값이 너무 커저 오버프로 오류가 일어 날 가능성이 있고, 또한 큰 음수로 쏠리게 되면 분자와 분모가 모두 0에 지나치게 가까워지면서 0으로 나누는 오류가 발생할 가능성도 있다. 



따라서 이 문제를 해결할 수 있는 방법으로  $x_i$중 최대값을 $x_{k}$라  할 때 위에서 구한 일반식에  $e^{x_k}$로 나구게 되면
$$
{y_i}={{e^{{x_i}-{x_k}}}\over{e^{{x_1}-{x_k}}}+...+{e^{{x_n}-{x_k}}}}\\\ \\
(x_k-x_j \ge 0,\ 0< {e^{{x_k}-{x_j}}}\leq 1)
$$
가 됩니다.  즉 분자와 분모에 존재하는 항들이 모두 0에서 1 사이의 값이 되 오버플로 오류가 방지되게 됩니다. 또한 분모에 ${e^{{x_k}-{x_k}}} = 1$ 인 항 존제하게되 0으로 나누는 오류도 방지가 됩니다.



## 3.2 소프트맥스 함수의 편미분

소프트맥스의 계산과정에서 입력벡터 **x**의 모든 x가 출력벡터 **y**의 모든 y에 영향을 미치므로 편미분은 모든$(x_j,y_j)$쌍에 대해 구해져야합니다.따라서 모든 편미분 ${\partial y_j\over\partial x_i}$ 값들로 구성된 2차원 행렬을 구해야 함니다.

우선 $i\neq j$ 에서의 편미분 ${\partial y_j\over\partial x_i}$ 를 구하면
$$
{\partial y_j\over\partial x_i} = {-{e^{x_j(e^{x_j}+...+e^{x_n})'}\over{(e^{x_1}+...+e^{x_n}})^2}}\\
=-{e^{x_j}e^{x_i}\over{(e^{x_1}+...+e^{x_n}})^2}\\
=-{e^{x_j}\over e^{x_1}+...+e^{x_n}}{e^{x_i}\over e^{x_1}+...+e^{x_n}}\\ \ \\
=-y_i y_j
$$
$i=j$ 인경우 편미분 ${\partial y_j\over\partial x_i}$ 를 구하면
$$
{\partial y_i\over\partial x_i} = {{e^{x_i}(e^{x_i}+...+e^{x_n})-e^{x_i}e^{x_i}\over{(e^{x_1}+...+e^{x_n}})^2}}\\
={e^{x_i}\over e^{x_1}+...+e^{x_n}}\left(1-{e^{x_i}\over e^{x_1}+...+e^{x_n}}\right)\\
=y_i-y_i^2
$$





## 3.3 소프트맥스 교차 엔트로피

2장에서 본것과 같이 두확률 분포 사이의 교차 엔트로피 정의는 다음과 같습니다.
$$
H(P,Q)=-\sum{p_i}\log{q_i}
$$
정답벡터 **y**를 확률분포 P로 로짓벡터 **a** 에 소프트맥스 함수를 적용하여 얻어낸 확률분포를 Q로 교차엔트로피 정의식에 따라 계산하면된다.

이때 소프트맥스 함수를 적용한 결과를 Q로 지정하면 확률의 성질상 모든 원솟값이 항상 0에서 1사이 값된다. 이때 0에 가까운 값이 되면 실수 표현 범위 문제로 인해 0으로 표현되는 경우까지 생기게 되면 값이 $-\infin$ 로 폭주하는 계산 오류가 발생한다.

이문제를 해결하기 위하여 아주작은 양수값$\epsilon$을 도입하여 다음과 같이 고쳐서 이용하게 됩니다.
$$
H(P,Q)=-\sum{p_i}\log{q_i}\approx -\sum{p_i}\log{(q_i+\epsilon)}
$$
이식에서 $\epsilon$ 는 큰 q에서는 아주작은 차이만 가져와 별다른 영향을 주지 않지만 0에 가까워지면 하한선 역할을 하며 폭주를 막아 안전하게 계산할 수 있게 해줍니다.

## 3.4 소프트맥스 교차 엔트로피의 편미분

소프트맥스 함수를 적용하여 얻어낸 확률분포를 Q로 했기 때문에
$$
H(P,Q)=-\sum{p_i}\log{q_i}
$$
에 식에서
$$
{\partial H\over\partial x_i}
=  -{{\partial \over \partial{x_i}} {\sum_{k=1}^n} {p_k} {logq_k}}
=  -{{\sum_{k=1}^n} {p_k} {\partial \over \partial {x_i}} {logq_k}}
=  -{{\sum_{k=1}^n} {p_k} {1 \over q_k}{\partial q_k \over \partial {x_i}}}
$$


이식에서 ${\partial q_k \over \partial {x_i}}$ 는 소프트맥스 함수의 편미분을 의미합니다.  위에서 설명 했듯이   $i\neq j$ 와 $i=j$ 인경우가 차이가 납니다. 

그래서 두 경우를 분리하여 처리하기 위해 먼저 위의 식을 다음과 같이 고칠 수 있습니다.


$$
-{{\sum_{k=1}^n} {p_k \over q_k}{\partial q_k \over \partial {x_i}}} 
= -{{\sum_{k=1}^n} {p_k \over q_k}{\partial q_k \over \partial {x_i}}} 
-{{\sum_{k\neq1}^n} {p_k \over q_k}{\partial q_k \over \partial {x_i}}}
= -{p_i \over q_i}{\partial q_i \over \partial {x_i}}
-{{\sum_{k\neq1}^n} {p_k \over q_k}{\partial q_k \over \partial {x_i}}}
$$
소프트 맥스의 편미분은 
$$
{\partial q_k \over \partial x_i} = -q_iq_k (i\neq k) \\ 
{\partial q_i \over \partial x_i} = q_i-q_i^2 (i = k)
$$


와 같이 되므로 
$$
{\partial H\over\partial x_i} = -{p_i \over q_i}{\partial q_i \over \partial {x_i}}
-{{\sum_{k\neq1}^n} {p_k \over q_k}{\partial q_k \over \partial {x_i}}} = p_iq_i-p_i+\sum_{k\neq i} p_kq_i -p_i = q_i\sum_{k=1}^n p_k-p_i
$$
가되고 $\sum_{k=1}^n p_k= 1$ 이므로 소프트맥스 교차 엔트로피의 편미분은
$$
{\partial H\over\partial x_i} = q_i-p_i
$$

와 같이 됩니다.




